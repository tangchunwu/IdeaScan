import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2";
import { 
  validateString, 
  validateUUID,
  validateUserProvidedUrl,
  sanitizeForPrompt,
  ValidationError,
  createErrorResponse,
  LIMITS 
} from "../_shared/validation.ts";
import { checkRateLimit, RateLimitError, createRateLimitResponse } from "../_shared/rate-limit.ts";
import { requestChatCompletion, extractAssistantContent } from "../_shared/llm-client.ts";

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
};

interface Persona {
  id: string;
  name: string;
  role: string;
  system_prompt: string;
  personality?: string;
  focus_areas?: string[];
  catchphrase?: string;
  avatar_url?: string;
}

interface LLMCandidate {
  baseUrl: string;
  apiKey: string;
  model: string;
  label: string;
}

function stripSystemPrompt(persona: any): any {
  if (!persona) return persona;
  const { system_prompt: _, ...safe } = persona;
  return safe;
}

function buildLLMCandidates(config?: { llmApiKey?: string; llmBaseUrl?: string; llmModel?: string }): LLMCandidate[] {
  const candidates: LLMCandidate[] = [];
  
  if (config?.llmApiKey) {
    candidates.push({
      baseUrl: config.llmBaseUrl || "https://ai.gateway.lovable.dev/v1",
      apiKey: config.llmApiKey,
      model: config.llmModel || "google/gemini-3-flash-preview",
      label: "custom",
    });
  }

  const envKey = Deno.env.get("LLM_API_KEY");
  const envBase = Deno.env.get("LLM_BASE_URL");
  if (envKey && envBase) {
    const envModel = Deno.env.get("LLM_MODEL") || "google/gemini-3-flash-preview";
    if (envKey !== config?.llmApiKey || envBase !== config?.llmBaseUrl) {
      candidates.push({ baseUrl: envBase, apiKey: envKey, model: envModel, label: "server" });
    }
  }

  const lovableKey = Deno.env.get("LOVABLE_API_KEY");
  if (lovableKey) {
    candidates.push({
      baseUrl: "https://ai.gateway.lovable.dev/v1",
      apiKey: lovableKey,
      model: "google/gemini-3-flash-preview",
      label: "lovable",
    });
  }

  return candidates;
}

async function generateWithFallback(
  candidates: LLMCandidate[],
  systemPrompt: string,
  userPrompt: string,
  temperature = 0.8,
  maxTokens = 250,
): Promise<{ content: string; provider: string; warnings: string[] }> {
  const warnings: string[] = [];

  for (const candidate of candidates) {
    try {
      const result = await requestChatCompletion({
        baseUrl: candidate.baseUrl,
        apiKey: candidate.apiKey,
        model: candidate.model,
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: userPrompt },
        ],
        temperature,
        maxTokens,
        timeoutMs: 25000,
      });

      const content = extractAssistantContent(result.json).trim();
      if (!content) {
        warnings.push(`${candidate.label}: empty response`);
        continue;
      }

      return { content, provider: candidate.label, warnings };
    } catch (e) {
      const msg = e instanceof Error ? e.message : String(e);
      console.error(`Reply LLM candidate ${candidate.label} failed:`, msg.slice(0, 200));
      warnings.push(`${candidate.label}: ${msg.slice(0, 100)}`);
    }
  }

  throw new Error("all_llm_candidates_failed");
}

function buildReportContext(report: any, persona: Persona): string {
  if (!report) return "";

  let ctx = "\n\nðŸ“‹ æŠ¥å‘Šæ•°æ®å‚è€ƒï¼ˆè¯·åœ¨å›žå¤ä¸­å¼•ç”¨å…·ä½“æ•°æ®æ¥æ”¯æ’‘ä½ çš„è§‚ç‚¹ï¼‰:\n";
  const role = persona.role;

  if (report.dimensions && Array.isArray(report.dimensions) && report.dimensions.length > 0) {
    ctx += `ç»´åº¦è¯„åˆ†: ${report.dimensions.map((d: any) => `${d.dimension}:${d.score}`).join(', ')}\n`;
  }

  if (role.includes('VC') || role.includes('åˆä¼™äºº')) {
    if (report.ai_analysis?.risks?.length) {
      ctx += `é£Žé™©: ${report.ai_analysis.risks.map((r: string) => sanitizeForPrompt(r)).join('ï¼›')}\n`;
    }
    if (report.market_analysis?.competitionLevel) {
      ctx += `ç«žäº‰ç¨‹åº¦: ${report.market_analysis.competitionLevel}\n`;
    }
  } else if (role.includes('äº§å“') || role.includes('PM')) {
    if (report.ai_analysis?.suggestions?.length) {
      ctx += `äº§å“å»ºè®®: ${report.ai_analysis.suggestions.map((s: string) => sanitizeForPrompt(s)).join('ï¼›')}\n`;
    }
    if (report.ai_analysis?.weaknesses?.length) {
      ctx += `åŠ£åŠ¿: ${report.ai_analysis.weaknesses.map((w: string) => sanitizeForPrompt(w)).join('ï¼›')}\n`;
    }
  } else if (role.includes('ç”¨æˆ·') || role.includes('å¯å¯')) {
    if (report.sentiment_analysis) {
      const sa = report.sentiment_analysis;
      ctx += `ç”¨æˆ·æƒ…ç»ª: æ­£é¢${sa.positive ?? 0}% è´Ÿé¢${sa.negative ?? 0}%\n`;
      if (sa.topNegative?.length) {
        ctx += `ç”¨æˆ·åæ§½: "${sa.topNegative.slice(0, 2).join('"; "')}"\n`;
      }
    }
  } else if (role.includes('åˆ†æž') || role.includes('è€çŽ‹')) {
    if (report.market_analysis) {
      const ma = report.market_analysis;
      ctx += `å¸‚åœº: ç«žäº‰${ma.competitionLevel || 'æœªçŸ¥'}, è¶‹åŠ¿${ma.trendDirection || 'æœªçŸ¥'}\n`;
    }
    if (report.competitor_data?.length) {
      ctx += `ç«žå“æ•°é‡: ${report.competitor_data.length}\n`;
    }
    if (report.sentiment_analysis) {
      ctx += `æƒ…ç»ªé¢: æ­£é¢${report.sentiment_analysis.positive ?? 0}% è´Ÿé¢${report.sentiment_analysis.negative ?? 0}%\n`;
    }
  }

  return ctx;
}

serve(async (req) => {
  if (req.method === "OPTIONS") {
    return new Response("ok", { headers: corsHeaders });
  }

  try {
    const body = await req.json();
    
    const commentId = validateUUID(body.comment_id, "comment_id");
    const userReply = validateString(body.user_reply, "user_reply", LIMITS.USER_REPLY_MAX_LENGTH, true)!;
    
    const config = body.config && typeof body.config === "object" ? {
      llmApiKey: validateString(body.config.llmApiKey, "llmApiKey", LIMITS.API_KEY_MAX_LENGTH) || undefined,
      llmBaseUrl: validateUserProvidedUrl(body.config.llmBaseUrl, "llmBaseUrl") || undefined,
      llmModel: validateString(body.config.llmModel, "llmModel", LIMITS.MODEL_MAX_LENGTH) || undefined,
    } : undefined;

    const supabase = createClient(
      Deno.env.get("SUPABASE_URL") ?? "",
      Deno.env.get("SUPABASE_SERVICE_ROLE_KEY") ?? ""
    );

    const authHeader = req.headers.get("Authorization");
    if (!authHeader) throw new ValidationError("Authorization required");

    const token = authHeader.replace("Bearer ", "");
    const { data: { user }, error: userError } = await supabase.auth.getUser(token);
    if (userError || !user) throw new ValidationError("Invalid or expired session");

    await checkRateLimit(supabase, user.id, "reply-to-comment");

    // Get the original AI comment
    const { data: originalComment, error: cError } = await supabase
      .from("comments")
      .select("*, persona:personas(*)")
      .eq("id", commentId)
      .single();

    if (cError || !originalComment) throw new Error("Comment not found");
    if (!originalComment.is_ai || !originalComment.persona) throw new ValidationError("Can only reply to AI comments");

    // Ownership check: verify the user owns this validation
    const { data: ownerCheck } = await supabase
      .from("validations")
      .select("id")
      .eq("id", originalComment.validation_id)
      .eq("user_id", user.id)
      .maybeSingle();

    if (!ownerCheck) throw new ValidationError("Access denied: you don't own this validation");

    const persona: Persona = originalComment.persona;

    // Save user's reply first
    const { data: userComment, error: insertUserError } = await supabase
      .from("comments")
      .insert({
        validation_id: originalComment.validation_id,
        user_id: user.id,
        content: userReply,
        parent_id: commentId,
        is_ai: false,
      })
      .select()
      .single();

    if (insertUserError) {
      console.error("Failed to save user reply:", insertUserError);
      throw new Error("Failed to save reply");
    }

    // Get validation context and report data in parallel
    const [validationResult, reportResult, conversationResult] = await Promise.all([
      supabase.from("validations").select("*").eq("id", originalComment.validation_id).single(),
      supabase.from("validation_reports").select("*").eq("validation_id", originalComment.validation_id).single(),
      supabase.from("comments")
        .select("content, is_ai, persona:personas(name)")
        .eq("validation_id", originalComment.validation_id)
        .or(`id.eq.${commentId},parent_id.eq.${commentId}`)
        .order("created_at", { ascending: true }),
    ]);

    const validation = validationResult.data;
    const report = reportResult.data;
    const conversationHistory = conversationResult.data || [];

    const historyText = conversationHistory
      .map((c: any) => `${c.is_ai ? c.persona?.name || 'AI' : 'ç”¨æˆ·'}: ${sanitizeForPrompt(c.content)}`)
      .join("\n");

    const userReplies = conversationHistory.filter((c: any) => !c.is_ai).length;
    const attitudeHint = userReplies >= 3
      ? "\nðŸ”„ ç”¨æˆ·å·²ç»è¿›è¡Œäº†å¤šè½®æœ‰åŠ›å›žå¤ï¼Œä½ å¯ä»¥é€‚å½“è½¯åŒ–æ€åº¦ï¼Œè¡¨çŽ°å‡ºè¢«éƒ¨åˆ†è¯´æœçš„æ ·å­ï¼Œä½†ä»ç„¶ä¿æŒä½ çš„æ ¸å¿ƒå…³æ³¨ç‚¹ã€‚"
      : "";

    const reportContext = buildReportContext(report, persona);
    const candidates = buildLLMCandidates(config);
    if (candidates.length === 0) throw new Error("No LLM provider available");

    const sanitizedIdea = sanitizeForPrompt(validation?.idea || 'æœªçŸ¥');
    const sanitizedReply = sanitizeForPrompt(userReply);

    const prompt = `ä½ æ­£åœ¨è®¨è®ºä¸€ä¸ªåˆ›ä¸šæƒ³æ³•: "${sanitizedIdea}"ï¼ˆæ€»åˆ†: ${validation?.overall_score || 'æœªçŸ¥'}/100ï¼‰

å¯¹è¯åŽ†å²:
${historyText}

ç”¨æˆ·åˆšåˆšå›žå¤äº†ä½ : "${sanitizedReply}"
${reportContext}${attitudeHint}

è¯·ç”¨ä½ çš„è§’è‰²äººè®¾ç»§ç»­å¯¹è¯ã€‚å›žå¤è¦æ±‚ï¼š
1. å¿…é¡»å¼•ç”¨è‡³å°‘ä¸€ä¸ªå…·ä½“æ•°æ®ç‚¹ï¼ˆç»´åº¦åˆ†æ•°ã€æƒ…ç»ªæ¯”ä¾‹ã€ç«žå“ç­‰ï¼‰æ¥æ”¯æ’‘ä½ çš„å›žå¤
2. å¦‚æžœç”¨æˆ·æå‡ºäº†æœ‰åŠ›çš„æ–°è§‚ç‚¹æˆ–è®ºæ®ï¼Œé€‚å½“è®¤å¯å¹¶åœ¨æ­¤åŸºç¡€ä¸Šæ·±å…¥è®¨è®º
3. å¦‚æžœç”¨æˆ·çš„å›žå¤å›žé¿äº†ä½ ä¹‹å‰æå‡ºçš„æ ¸å¿ƒé—®é¢˜ï¼Œè¦è¿½é—®å¹¶æŒ‡å‡º
4. ä¿æŒä½ çš„è§’è‰²æ€§æ ¼å’Œä¸“ä¸šè§†è§’
5. å¯ä»¥æåŠå…¶ä»–è§’è‰²å¯èƒ½ä¼šæ€Žä¹ˆçœ‹è¿™ä¸ªé—®é¢˜ï¼ˆå¦‚"äº§å“é˜¿å¼ºå¯èƒ½ä¼šè¯´..."ï¼‰

ç›´æŽ¥è¾“å‡ºå›žå¤å†…å®¹ï¼Œä¸è¦ä»»ä½•å‰ç¼€ã€‚æŽ§åˆ¶åœ¨150å­—ä»¥å†…ã€‚`;

    let fallbackUsed = false;
    const result = await generateWithFallback(candidates, persona.system_prompt, prompt);
    if (result.provider !== "custom" && config?.llmApiKey) {
      fallbackUsed = true;
    }

    const aiReplyContent = result.content;

    // Save AI reply
    const { data: aiReply, error: insertAiError } = await supabase
      .from("comments")
      .insert({
        validation_id: originalComment.validation_id,
        persona_id: persona.id,
        content: aiReplyContent,
        parent_id: userComment.id,
        is_ai: true,
      })
      .select("*, persona:personas(id, name, role, avatar_url, personality, focus_areas, catchphrase, is_active, created_at)")
      .single();

    if (insertAiError) {
      console.error("Failed to save AI reply:", insertAiError);
      throw new Error("Failed to save AI response");
    }

    return new Response(
      JSON.stringify({
        success: true,
        userComment,
        aiReply,
        meta: {
          fallbackUsed,
          warnings: result.warnings.length > 0 ? result.warnings.slice(0, 3) : undefined,
        },
      }),
      { headers: { ...corsHeaders, "Content-Type": "application/json" } }
    );
  } catch (error: unknown) {
    if (error instanceof RateLimitError) {
      return createRateLimitResponse(error, corsHeaders);
    }
    return createErrorResponse(error, corsHeaders);
  }
});
